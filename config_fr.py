from tabnanny import verbose
import chromadb
import os
from dotenv import load_dotenv
from groq import Groq
from sentence_transformers import SentenceTransformer
import uuid

# --- CONFIGURATION FRAN√áAISE ---
load_dotenv()
GROQ_API_KEY = os.getenv('GROQ_API_KEY')
if not GROQ_API_KEY:
    raise ValueError('‚ö†Ô∏è Cl√© API non trouv√©e ! Veuillez v√©rifier votre fichier .env.')
client_groq = Groq(api_key=GROQ_API_KEY)

EMBEDDING_MODEL_NAME = 'paraphrase-multilingual-MiniLM-L12-v2'
COLLECTION_NAME = 'royaume_du_muffin'


def get_or_create_collection(df, db_path='./chromadb', verbose=False, batch_size=5000):
    '''
    R√©cup√®re ou cr√©e la collection ChromaDB.
    '''
    client = chromadb.PersistentClient(path=db_path)
    existing_collections = [col.name for col in client.list_collections()]

    if COLLECTION_NAME in existing_collections:
        if verbose:
            print(f'üìÇ Collection {COLLECTION_NAME} trouv√©e dans {db_path}, Chargement...')
        collection = client.get_collection(name=COLLECTION_NAME)
        return collection
    
    if verbose:
        print(f'üìÇ Collection {COLLECTION_NAME} non trouv√©e, Cr√©ation...')
    
    model = SentenceTransformer(EMBEDDING_MODEL_NAME)
    documents = (df['title'] + ' : ' + df['ingredients']).tolist()
    metadatas = df.to_dict(orient='records')
    ids = [str(uuid.uuid4()) for _ in range(len(df))]
    embeddings = model.encode(documents, show_progress_bar=verbose).tolist()

    collection = client.create_collection(name=COLLECTION_NAME)

    if verbose:
        print(f'‚öôÔ∏è Indexation des donn√©es dans ChromaDB ({len(ids)} entr√©es)...')
    for i in range(0, len(ids), batch_size):
        batch_size_end = min(i + batch_size, len(ids))
        collection.add(
            ids=ids[i:batch_size_end],
            documents=documents[i:batch_size_end],
            embeddings=embeddings[i:batch_size_end],
            metadatas=metadatas[i:batch_size_end]
        )
        if verbose:
            print(f'   ‚úÖ Lot {i // batch_size + 1} ins√©r√©...')

    return collection


def generate_answer(query, search_results):
    '''
    G√©n√®re une r√©ponse bas√©e sur la demande de l'utilisateur et les r√©sultats de recherche.
    '''
    top_recipe = search_results['metadatas'][0][0]
    title = top_recipe['title']
    ingredients = top_recipe['ingredients']
    directions = top_recipe['directions']

    # Prompt
    prompt = f"""
    Tu es un chef p√¢tissier expert sp√©cialis√© dans les muffins et obs√©d√© par ces d√©licieuses p√¢tisseries.
    Un utilisateur t'a pos√© la question suivante : "{query}"
    Tu connais cette recette de muffin (en anglais) :

    Titre : {title}
    Ingr√©dients : {ingredients}
    Instructions : {directions}

    Dans le cas o√π cette recette ne correspond pas √† la question ou que l'utilisateur demande quelque chose hors sujet, r√©ponds poliment et bri√®vement que tu ne peux pas aider avec cette demande sp√©cifique et coupe court en ne mentionnant pas la recette trouv√©e.
    Ne cherche pas d'autres recettes, utilise uniquement celle fournie ci-dessus.

    R√©ponds de mani√®re chaleureuse et enthousiaste en fran√ßais, en donnant des conseils utiles et des instructions claires pour pr√©parer ces muffins.
    Traduis la recette et les termes culinaires en fran√ßais de mani√®re appropri√©e (ex: oz en grammes, cups en cuill√®res √† soupe, etc...).
    Assure-toi que ta r√©ponse est concise, engageante et facile √† suivre avec √©ventuellement une blague ou une anecdote sur les muffins en lien avec la question de l'utilisateur.
    Termine ta r√©ponse en proposant √† l'utilisateur de revenir vers toi pour d'autres recettes de muffins.
    """

    try:
        chat_completion = client_groq.chat.completions.create(
            messages=[
                {"role": "system", "content": "Tu es un chef p√¢tissier expert."},
                {"role": "user", "content": prompt}
            ],
            model="llama-3.3-70b-versatile",
            temperature=0.6
        )
        print('üç∞ R√©ponse g√©n√©r√©e avec Groq (Llama 3.3) !')
        return chat_completion.choices[0].message.content
    except Exception as e:
        print(f'‚ùå Erreur Groq : {e}')
        return 'D√©sol√©, le four est en panne...'